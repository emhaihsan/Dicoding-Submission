# -*- coding: utf-8 -*-
"""Project 2: Membuat Model Machine Learning dengan Data Time Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ndVMfUXZvT2PVtd1nsAEFNb1UZsX7b-r
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
import requests
import zipfile
from io import BytesIO
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.optimizers import Adam

# Download Data Air Quality dari UCI
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip'
response = requests.get(url)

# Unzip the content
with zipfile.ZipFile(BytesIO(response.content), 'r') as z:
    # Get the list of files in the ZIP archive
    file_list = z.namelist()

    # Look for the first CSV file
    csv_file = next((file for file in file_list if file.endswith('.csv')), None)

    if csv_file:
        # Load the CSV file
        with z.open(csv_file) as f:
            df = pd.read_csv(f, delimiter=';', decimal=',')

        print("Dataset loaded successfully.")
    else:
        print("No CSV file found in the ZIP archive.")

print(f"Jumlah sampel data {len(df)}")

# Visualize the raw data
plt.figure(figsize=(15, 6))
plt.plot(df['CO(GT)'])
plt.title('Raw Time Series Data - CO(GT)')
plt.xlabel('Index')
plt.ylabel('CO(GT)')
plt.show()

# Visualize the distribution of CO(GT)
plt.figure(figsize=(10, 6))
plt.hist(df['CO(GT)'], bins=30, edgecolor='black')
plt.title('Distribution of CO(GT)')
plt.xlabel('CO(GT)')
plt.ylabel('Frequency')
plt.show()

# Bersihkan data (misalnya, mengganti nilai -200 menjadi NaN)
df['CO(GT)'] = df['CO(GT)'].replace(-200, np.nan)

# Gabungkan kolom Date dan Time menjadi satu kolom datetime
df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H.%M.%S')

# Hapus kolom Date dan Time yang tidak diperlukan lagi
df = df.drop(['Date', 'Time'], axis=1)

# Isi nilai yang hilang dengan interpolasi linear
df['CO(GT)'] = df['CO(GT)'].interpolate()

# Set datetime sebagai indeks
df = df.set_index('Datetime')

# Visualisasi data
plt.figure(figsize=(15, 6))
plt.plot(df.index, df['CO(GT)'])
plt.title('Time Series Data - CO(GT)')
plt.xlabel('Datetime')
plt.ylabel('CO(GT)')
plt.show()

# Preprocessing data
scaler = MinMaxScaler()
df['CO(GT)_scaled'] = scaler.fit_transform(df[['CO(GT)']])

# Visualize the scaled data
plt.figure(figsize=(15, 6))
plt.plot(df.index, df['CO(GT)_scaled'])
plt.title('Scaled Time Series Data - CO(GT)')
plt.xlabel('Datetime')
plt.ylabel('Scaled CO(GT)')
plt.show()

# Membuat dataset windowed
def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

# Split data menjadi train dan validation set
train_size = int(len(df) * 0.8)
train, val = df.iloc[:train_size], df.iloc[train_size:]

# Parameter model
window_size = 24  # Contoh window size (sesuaikan dengan kebutuhan)
batch_size = 32
shuffle_buffer_size = 1000
learning_rate = 0.001

# Membuat dataset windowed untuk training dan validation
train_ds = windowed_dataset(train['CO(GT)_scaled'], window_size, batch_size, shuffle_buffer_size)
val_ds = windowed_dataset(val['CO(GT)_scaled'], window_size, batch_size, shuffle_buffer_size)

# Membangun model sequential dengan LSTM
model = Sequential([
    LSTM(50, input_shape=(window_size, 1), return_sequences=True),
    LSTM(100),
    Dense(1)
])

# Compile model dengan Adam optimizer
optimizer = Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])

model.summary()

# Membuat callback
# Model Checkpoint untuk menyimpan model terbaik selama pelatihan dengan berpatokan pada nilai val loss
# Menggunakan EarlyStopping agar model berhenti training ketika performanya tidak meningkat setelah 5 epoch
checkpoint_path = "model.h5"
checkpoint_callback = ModelCheckpoint(checkpoint_path,monitor='val_loss',save_best_only=True)
early_stopping_callback = EarlyStopping(patience=5, restore_best_weights=True)

# Train the model
history = model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=[checkpoint_callback, early_stopping_callback])

# Evaluate model
result = model.evaluate(val_ds)

# Visualize training history
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss History')
plt.xlabel('Epoch')
plt.ylabel('Loss (Huber)')
plt.legend()
plt.show()

# Visualize training history
plt.figure(figsize=(10, 6))
plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.title('MAE History')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.show()

# result menyimpan 2 nilai, indeks 0 merepresentasikan loss, indeks 1 merepresentasikan mae
# indeks 0 disimpan ke variabel _ untuk menandakan bahwa variabel ini diabaikan
# indeks 1 disimpan ke variabel val_mae untuk kemudian dicek apakah sudah memenuhi kriteria atau belum
_ , val_mae = result

# Check if MAE meets the criteria
mae_threshold = 0.1 * (df['CO(GT)'].max() - df['CO(GT)'].min())

print(f"Rerata Konsentrasi CO maksimal : {df['CO(GT)'].max()}")
print(f"Rerata Konsentrasi CO minimal : {df['CO(GT)'].min()}")
print(f"Threshold 10% MAE : {mae_threshold}")
print(f"MAE pada data validasi: {val_mae}")
print(f"Selisih MAE model dengan threshold :{mae_threshold - val_mae}")
if val_mae < mae_threshold:
  print("Model memenuhi kriteria MAE < 10% skala data")
else:
  print("Model belum memenuhi kriteria MAE < 10% skala data. Coba tuning parameternya kembali")

"""## Project 2 : Membuat Model Machine Learning dengan Data Time Series

Nama : Muhammad Ihsan

email : emhihsan@gmail.com
"""